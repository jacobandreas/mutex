{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.utils.data as torch_data\n",
    "import torch.nn.functional as F\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import combinations, product\n",
    "from mutex import EncDec, Vocab, batch_seqs, Mutex\n",
    "from absl import app, flags\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_symbols_list   = set(['dax', 'lug', 'wif', 'zup', 'fep', 'blicket', 'kiki', 'tufa', 'gazzer'])\n",
    "output_symbols_list  = set(['RED', 'YELLOW', 'GREEN', 'BLUE', 'PURPLE', 'PINK'])\n",
    "def encode(data,vocab):\n",
    "    encoded = []\n",
    "    for (inp,out) in data:\n",
    "        encoded.append(( [vocab.sos()]  + vocab.encode(inp) + [vocab.eos()], [vocab.sos()] + vocab.encode(out) + [vocab.eos()]))\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1  = lambda w:  w + w + w\n",
    "f2  = lambda w1, w2: w1 + w2 + w1\n",
    "f3  = lambda w1, w2: w2 + w1\n",
    "get = lambda vals, hsh: [hsh[val] for val in vals]\n",
    "\n",
    "def unary(f, w, colormap, fmap):\n",
    "    return (w + [fmap[f]], get(f(w),colormap))\n",
    "\n",
    "def binary(f, w1, w2, colormap, fmap):\n",
    "    return (w1 + [fmap[f]] + w2, get(f(w1,w2),colormap))\n",
    "\n",
    "def binary_mapped(f, p1, p2, fmap):\n",
    "    w1, o1 = p1\n",
    "    w2, o2 = p2\n",
    "    return (w1 + [fmap[f]] + w2, f(o1,o2))\n",
    "\n",
    "def samplef(fs,words,colormap,fmap):\n",
    "    f = random.choice(fs)\n",
    "    if f == f1:\n",
    "        w = random.choice(tuple(words))\n",
    "        return unary(f, [w], colormap, fmap)\n",
    "    else:\n",
    "        w1, w2 = random.choice(list(product(words,words)))\n",
    "        return binary(f, [w1], [w2], colormap, fmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fig2_exp(input_symbols, output_symbols):\n",
    "        words     = set(random.sample(input_symbols,4))\n",
    "        colors    = set(random.sample(output_symbols,4))\n",
    "        colormap  = dict(zip(words, colors))\n",
    "        fnames    = random.sample(input_symbols - words,3)\n",
    "        fmap      = dict(zip([f1,f2,f3], fnames))\n",
    "        print(\"color map: \", colormap)\n",
    "        print(\"function names: \", fnames)\n",
    "        \n",
    "        trn,tst  = [],[]\n",
    "        #Primitives\n",
    "        for (i,w) in enumerate(words):\n",
    "            trn.append(([w],get([w],colormap)))\n",
    "            \n",
    "            \n",
    "        combs = set(combinations(words, r=2))\n",
    "        #Function 1 : x f1 -> X X X \n",
    "        trnwords = set(random.sample(words,2))\n",
    "        tstwords = set(random.sample(words-trnwords,2)) \n",
    "        for w in trnwords:\n",
    "            trn.append(unary(f1,[w],colormap, fmap)) \n",
    "        for w in tstwords:\n",
    "            tst.append(unary(f1,[w],colormap, fmap)) \n",
    "        \n",
    "        #Function 2 : x f2 y-> X Y X \n",
    "        trnpairs = set(random.sample(combs,2))\n",
    "        tstpairs = set(random.sample(combs-trnpairs,2)) \n",
    "        for (w1,w2) in trnpairs:\n",
    "            trn.append(binary(f2,[w1],[w2],colormap, fmap))\n",
    "        for (w1,w2) in tstpairs:\n",
    "            tst.append(binary(f2,[w1],[w2],colormap, fmap))\n",
    "                       \n",
    "        #Function 3 : x f3 y-> Y X\n",
    "        trnpairs = set(random.sample(combs,2))\n",
    "        tstpairs = set(random.sample(combs-trnpairs,2)) \n",
    "        for (w1,w2) in trnpairs:\n",
    "            trn.append(binary(f3, [w1], [w2], colormap, fmap))\n",
    "        for (w1,w2) in tstpairs:\n",
    "            tst.append(binary(f3, [w1], [w2], colormap, fmap))\n",
    "            \n",
    "        #Study Compositions\n",
    "        for i in range(2):\n",
    "            w1 = random.choice(tuple(words))\n",
    "            p1 = ([w1], [colormap[w1]])\n",
    "            center  = random.choice((f2,f3))\n",
    "            p2 = samplef((f1,),words,colormap,fmap)\n",
    "            trn.append(binary_mapped(center,p1,p2,fmap))\n",
    "        \n",
    "        # Order of The Operations: fother (*) always before fcenter (+)\n",
    "        if random.random() > 0.5:\n",
    "            fcenter,fother = f2,f3\n",
    "        else:\n",
    "            fcenter,fother = f3,f2\n",
    "\n",
    "        for i in range(2): \n",
    "            w1 = random.choice(tuple(words))\n",
    "            p1 = ([w1], [colormap[w1]])\n",
    "            center = fcenter\n",
    "            p2 = samplef((fother,),words,colormap,fmap)\n",
    "            if i == 1: p2, p1 = p1,p2\n",
    "            trn.append(binary_mapped(center,p1,p2,fmap))\n",
    "        \n",
    "        #Test Compositions\n",
    "        for i in range(2):\n",
    "            w1 = random.choice(tuple(words))\n",
    "            p1 = ([w1], [colormap[w1]])\n",
    "            center  = random.choice((f2,f3))\n",
    "            p2 = samplef((f1,),words,colormap,fmap)\n",
    "            tst.append(binary_mapped(center,p1,p2,fmap))\n",
    "        \n",
    "        w1 = random.choice(tuple(words))\n",
    "        p1 = ([w1], [colormap[w1]])\n",
    "        center = fcenter\n",
    "        p2 = samplef((fother,),words,colormap,fmap)\n",
    "        if random.random() > 0.5: p2, p1 = p1,p2\n",
    "        tst.append(binary_mapped(center,p1,p2,fmap))\n",
    "                \n",
    "        for i in range(2):\n",
    "            p1 = samplef((f1,),words,colormap,fmap)\n",
    "            center  = fcenter\n",
    "            p2 = samplef((fother,),words,colormap,fmap)\n",
    "            if random.random() > 0.5: p2, p1 = p1,p2\n",
    "            tst.append(binary_mapped(center,p1,p2,fmap))\n",
    "            \n",
    "        return trn,tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color map:  {'kiki': 'GREEN', 'wif': 'PURPLE', 'fep': 'BLUE', 'blicket': 'PINK'}\n",
      "function names:  ['dax', 'gazzer', 'zup']\n"
     ]
    }
   ],
   "source": [
    "study, test = generate_fig2_exp(input_symbols_list, output_symbols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['kiki'], ['GREEN']),\n",
       " (['wif'], ['PURPLE']),\n",
       " (['fep'], ['BLUE']),\n",
       " (['blicket'], ['PINK']),\n",
       " (['wif', 'dax'], ['PURPLE', 'PURPLE', 'PURPLE']),\n",
       " (['blicket', 'dax'], ['PINK', 'PINK', 'PINK']),\n",
       " (['kiki', 'gazzer', 'wif'], ['GREEN', 'PURPLE', 'GREEN']),\n",
       " (['kiki', 'gazzer', 'fep'], ['GREEN', 'BLUE', 'GREEN']),\n",
       " (['wif', 'zup', 'blicket'], ['PINK', 'PURPLE']),\n",
       " (['kiki', 'zup', 'blicket'], ['PINK', 'GREEN']),\n",
       " (['fep', 'zup', 'kiki', 'dax'], ['GREEN', 'GREEN', 'GREEN', 'BLUE']),\n",
       " (['kiki', 'gazzer', 'blicket', 'dax'],\n",
       "  ['GREEN', 'PINK', 'PINK', 'PINK', 'GREEN']),\n",
       " (['fep', 'gazzer', 'kiki', 'zup', 'wif'],\n",
       "  ['BLUE', 'PURPLE', 'GREEN', 'BLUE']),\n",
       " (['blicket', 'zup', 'blicket', 'gazzer', 'wif'],\n",
       "  ['PINK', 'PINK', 'PURPLE', 'PINK', 'PINK'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['kiki', 'dax'], ['GREEN', 'GREEN', 'GREEN']),\n",
       " (['fep', 'dax'], ['BLUE', 'BLUE', 'BLUE']),\n",
       " (['wif', 'gazzer', 'blicket'], ['PURPLE', 'PINK', 'PURPLE']),\n",
       " (['wif', 'gazzer', 'fep'], ['PURPLE', 'BLUE', 'PURPLE']),\n",
       " (['fep', 'zup', 'blicket'], ['PINK', 'BLUE']),\n",
       " (['wif', 'zup', 'fep'], ['BLUE', 'PURPLE']),\n",
       " (['wif', 'gazzer', 'kiki', 'dax'],\n",
       "  ['PURPLE', 'GREEN', 'GREEN', 'GREEN', 'PURPLE']),\n",
       " (['fep', 'gazzer', 'wif', 'dax'],\n",
       "  ['BLUE', 'PURPLE', 'PURPLE', 'PURPLE', 'BLUE']),\n",
       " (['kiki', 'gazzer', 'kiki', 'zup', 'fep'],\n",
       "  ['GREEN', 'BLUE', 'GREEN', 'GREEN']),\n",
       " (['kiki', 'zup', 'fep', 'gazzer', 'wif', 'dax'],\n",
       "  ['BLUE', 'GREEN', 'PURPLE', 'PURPLE', 'PURPLE', 'BLUE', 'GREEN']),\n",
       " (['fep', 'dax', 'gazzer', 'blicket', 'zup', 'kiki'],\n",
       "  ['BLUE', 'BLUE', 'BLUE', 'GREEN', 'PINK', 'BLUE', 'BLUE', 'BLUE'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "flags_dict = FLAGS._flags()\n",
    "keys_list = [keys for keys in flags_dict]\n",
    "for keys in keys_list: delattr(FLAGS,keys)\n",
    "flags.DEFINE_integer(\"dim\", 200, \"trasnformer dimension\")\n",
    "flags.DEFINE_integer(\"n_layers\", 1, \"number of rnn layers\")\n",
    "flags.DEFINE_integer(\"n_batch\", 1, \"batch size\")\n",
    "flags.DEFINE_integer(\"n_epochs\",100, \"number of training epochs\")\n",
    "flags.DEFINE_float(\"lr\", 0.001, \"learning rate\")\n",
    "flags.DEFINE_float(\"dropout\", 0.0, \"dropout\")\n",
    "flags.DEFINE_string(\"save_model\", \"model.m\", \"model save location\")\n",
    "flags.DEFINE_integer(\"seed\", 0, \"random seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mutex.ipynb']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS(['mutex.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    inp, out = zip(*batch)\n",
    "    inp = batch_seqs(inp).to(DEVICE)\n",
    "    out = batch_seqs(out).to(DEVICE)\n",
    "    return inp, out\n",
    "\n",
    "def pretrain(model, train_dataset, val_dataset):\n",
    "    opt = optim.Adam(model.parameters(), lr=FLAGS.lr)\n",
    "    train_loader = torch_data.DataLoader(\n",
    "        train_dataset, batch_size=FLAGS.n_batch, shuffle=True, \n",
    "        collate_fn=collate\n",
    "    )\n",
    "    best_loss  = np.inf\n",
    "    for i_epoch in range(FLAGS.n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_batches = 0\n",
    "        for inp, _ in train_loader:\n",
    "            x = inp[:-1,:]\n",
    "            pred, *extras = model(None, x.shape[0], x)\n",
    "            output = pred.view(-1, len(model.vocab))\n",
    "            loss = model.nllreduce(output,inp[1:, :].view(-1))\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            opt.step()\n",
    "            train_loss    += loss.item() * inp.shape[1]\n",
    "            train_batches += inp.shape[1]\n",
    "\n",
    "        if (i_epoch + 1) % 3 != 0:\n",
    "            continue\n",
    "\n",
    "        curr_loss = train_loss / train_batches\n",
    "        best_loss = min(best_loss, curr_loss)\n",
    "        print(curr_loss)\n",
    "        torch.save(model.state_dict(), FLAGS.save_model)\n",
    "\n",
    "    print(\"best_loss\", best_loss)\n",
    "\n",
    "    \n",
    "    \n",
    "def train(model, train_dataset, val_dataset):\n",
    "    opt = optim.Adam(model.parameters(), lr=FLAGS.lr)\n",
    "    train_loader = torch_data.DataLoader(\n",
    "        train_dataset, batch_size=FLAGS.n_batch, shuffle=True, \n",
    "        collate_fn=collate\n",
    "    )\n",
    "    best_f1  = -np.inf\n",
    "    best_acc = -np.inf\n",
    "    for i_epoch in range(FLAGS.n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_batches = 0\n",
    "        for inp, out in train_loader:\n",
    "            nll = model(inp, out)\n",
    "            loss = nll.mean()\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            opt.step()\n",
    "            train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "\n",
    "        if (i_epoch + 1) % 3 != 0:\n",
    "            continue\n",
    "\n",
    "        print(train_loss / train_batches)\n",
    "        acc, f1 = validate(model, val_dataset)\n",
    "        print(f\"epoch_{i_epoch}_acc\", acc)\n",
    "        print(f\"epoch_{i_epoch}_f1\", f1)\n",
    "        best_f1 = max(best_f1, f1)\n",
    "        best_acc = max(best_acc, acc)\n",
    "        print()\n",
    "        torch.save(model.state_dict(), FLAGS.save_model)\n",
    "\n",
    "    print(\"final_acc\", acc)\n",
    "    print(\"final_f1\", f1)\n",
    "    print(\"best_acc\", best_acc)\n",
    "    print(\"best_f1\", best_f1)\n",
    "\n",
    "def eval_format(vocab, seq):\n",
    "    if vocab.eos() in seq:\n",
    "        seq = seq[:seq.index(vocab.eos())+1]\n",
    "    seq = seq[1:-1]\n",
    "    return vocab.decode(seq)\n",
    "\n",
    "def validate(model, val_dataset, vis=False, tag=[]):\n",
    "    model.eval()\n",
    "    first = True\n",
    "    val_loader = torch_data.DataLoader(\n",
    "        val_dataset, batch_size=FLAGS.n_batch, shuffle=True, \n",
    "        collate_fn=collate\n",
    "    )\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    with torch.no_grad():\n",
    "        for inp, out in val_loader:\n",
    "            pred, _ = model.sample(inp, temp=1.0, max_len=40, greedy=True)\n",
    "            for i, seq in enumerate(pred):\n",
    "                ref = out[:, i].detach().cpu().numpy().tolist()\n",
    "                ref = eval_format(model.vocab, ref)\n",
    "                pred_here = eval_format(model.vocab, pred[i])\n",
    "                correct_here = pred_here == ref\n",
    "                correct += correct_here\n",
    "                tp_here = len([p for p in pred_here if p in ref])\n",
    "                tp += tp_here\n",
    "                fp_here = len([p for p in pred_here if p not in ref])\n",
    "                fp += fp_here\n",
    "                fn_here = len([p for p in ref if p not in pred_here])\n",
    "                fn += fn_here\n",
    "                path = \"/\" + \"/\".join(tag)\n",
    "                if vis:\n",
    "                    print(f\"@{path}/{total}\", correct_here, tp_here, fp_here, fn_here)\n",
    "                    inp_lst = inp[:, i].detach().cpu().numpy().tolist()\n",
    "                    print(eval_format(model.vocab, inp_lst))\n",
    "                    print(\"gold\", ref)\n",
    "                    print(\"pred\", pred_here)\n",
    "                    print(pred_here == ref)\n",
    "                    print()\n",
    "                total += 1\n",
    "\n",
    "    acc = correct / total\n",
    "    prec = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "    if prec == 0 or rec == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2 * prec * rec / (prec + rec)\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model=None):\n",
    "    np.random.seed(FLAGS.seed)\n",
    "    torch.manual_seed(FLAGS.seed)\n",
    "    vocab = Vocab()\n",
    "    for sym in input_symbols_list.union(output_symbols_list): \n",
    "        vocab.add(sym)\n",
    "        \n",
    "    study, test = generate_fig2_exp(input_symbols_list, output_symbols_list)\n",
    "    \n",
    "    train_items, test_items = encode(study,vocab), encode(test,vocab)\n",
    "    \n",
    "    outlist = list(output_symbols_list)\n",
    "    def py(batch, max_len):\n",
    "        ys = []\n",
    "        for i in range(batch):\n",
    "            length = random.randrange(1,max_len-1)\n",
    "            symbols = random.choices(outlist, k=length)\n",
    "            encoded = [vocab.sos()]  +  vocab.encode(symbols) + [vocab.eos()]\n",
    "            ys.append(encoded)\n",
    "        return batch_seqs(ys).to(DEVICE)\n",
    "        \n",
    "    if model is None:\n",
    "        model = Mutex(vocab, \n",
    "                      FLAGS.dim, \n",
    "                      FLAGS.dim, py, \n",
    "                      copy=False, \n",
    "                      n_layers=FLAGS.n_layers, \n",
    "                      self_att=False, \n",
    "                      dropout=FLAGS.dropout,\n",
    "                      lamda=0.1,\n",
    "                      Nsample=50).to(DEVICE)\n",
    "        \n",
    "    pretrain(model.px, train_items + test_items, test_items)\n",
    "\n",
    "    print(\"px samples: \")\n",
    "    print(model.sample_px(5))\n",
    "    print(\"py samples: \")\n",
    "    print(model.sample_py(5))\n",
    "    train(model, train_items, test_items)\n",
    "    return model, study, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import mutex\n",
    "importlib.reload(mutex)\n",
    "from mutex import EncDec, Vocab, batch_seqs, Mutex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color map:  {'dax': 'GREEN', 'gazzer': 'PURPLE', 'fep': 'RED', 'blicket': 'PINK'}\n",
      "function names:  ['tufa', 'zup', 'kiki']\n",
      "1.2795107913017274\n",
      "1.2489318227767945\n",
      "1.1783106231689453\n",
      "1.1710542941093445\n",
      "1.0849985432624818\n",
      "1.0763975143432618\n",
      "1.0682159817218781\n",
      "1.025890244245529\n",
      "0.9886056041717529\n",
      "1.0331876802444457\n",
      "1.005784273147583\n",
      "1.0127952337265014\n",
      "1.0041201949119567\n",
      "0.9804985404014588\n",
      "0.9978327453136444\n",
      "0.9939659976959229\n",
      "0.9818767368793487\n",
      "1.0010983395576476\n",
      "0.9893605232238769\n",
      "0.9752936637401581\n",
      "0.9634255373477936\n",
      "0.9820947217941284\n",
      "0.9933621227741242\n",
      "0.9714501488208771\n",
      "0.9614493381977082\n",
      "0.9651017999649047\n",
      "0.9574231529235839\n",
      "0.9480963158607483\n",
      "0.9615914595127105\n",
      "0.9597129058837891\n",
      "0.9542734599113465\n",
      "0.9421617722511292\n",
      "0.9527459383010864\n",
      "best_loss 0.9421617722511292\n",
      "px samples: \n",
      "[['<s>', 'gazzer', 'kiki', 'blicket', '</s>'], ['<s>', 'gazzer', 'kiki', 'blicket', '</s>'], ['<s>', 'gazzer', 'tufa', '</s>'], ['<s>', 'gazzer', 'tufa', '</s>'], ['<s>', 'gazzer', 'zup', 'dax', 'tufa', '</s>']]\n",
      "py samples: \n",
      "[['<s>', 'RED', 'GREEN', 'PURPLE', 'PINK', 'YELLOW', '</s>'], ['<s>', 'PURPLE', 'PINK', 'PURPLE', '</s>', '<pad>', '<pad>'], ['<s>', 'PURPLE', 'BLUE', 'RED', '</s>', '<pad>', '<pad>'], ['<s>', 'YELLOW', 'BLUE', 'GREEN', '</s>', '<pad>', '<pad>'], ['<s>', 'PURPLE', 'GREEN', 'BLUE', 'PINK', 'RED', '</s>']]\n",
      "2.179842914853777\n",
      "epoch_2_acc 0.0\n",
      "epoch_2_f1 0.7272727272727272\n",
      "\n",
      "1.3551587803023202\n",
      "epoch_5_acc 0.09090909090909091\n",
      "epoch_5_f1 0.8070175438596492\n",
      "\n",
      "1.0089818494660514\n",
      "epoch_8_acc 0.09090909090909091\n",
      "epoch_8_f1 0.8985507246376812\n",
      "\n",
      "0.868044125182288\n",
      "epoch_11_acc 0.18181818181818182\n",
      "epoch_11_f1 0.8666666666666667\n",
      "\n",
      "0.8146855575697762\n",
      "epoch_14_acc 0.2727272727272727\n",
      "epoch_14_f1 0.8358208955223881\n",
      "\n",
      "0.8372308484145573\n",
      "epoch_17_acc 0.18181818181818182\n",
      "epoch_17_f1 0.8524590163934426\n",
      "\n",
      "0.8242807558604649\n",
      "epoch_20_acc 0.18181818181818182\n",
      "epoch_20_f1 0.8571428571428571\n",
      "\n",
      "0.7999274177210671\n",
      "epoch_23_acc 0.2727272727272727\n",
      "epoch_23_f1 0.8750000000000001\n",
      "\n",
      "0.8136106346334729\n",
      "epoch_26_acc 0.09090909090909091\n",
      "epoch_26_f1 0.8484848484848485\n",
      "\n",
      "0.7923125156334468\n",
      "epoch_29_acc 0.18181818181818182\n",
      "epoch_29_f1 0.8571428571428571\n",
      "\n",
      "0.8245843648910522\n",
      "epoch_32_acc 0.18181818181818182\n",
      "epoch_32_f1 0.8437500000000001\n",
      "\n",
      "0.8280714665140424\n",
      "epoch_35_acc 0.18181818181818182\n",
      "epoch_35_f1 0.8571428571428571\n",
      "\n",
      "0.8054413369723729\n",
      "epoch_38_acc 0.18181818181818182\n",
      "epoch_38_f1 0.8437500000000001\n",
      "\n",
      "0.7994433854307447\n",
      "epoch_41_acc 0.18181818181818182\n",
      "epoch_41_f1 0.8437500000000001\n",
      "\n",
      "0.8181037519659314\n",
      "epoch_44_acc 0.18181818181818182\n",
      "epoch_44_f1 0.8571428571428571\n",
      "\n",
      "0.8106076717376709\n",
      "epoch_47_acc 0.18181818181818182\n",
      "epoch_47_f1 0.8437500000000001\n",
      "\n",
      "0.8021796728883471\n",
      "epoch_50_acc 0.18181818181818182\n",
      "epoch_50_f1 0.8437500000000001\n",
      "\n",
      "0.8225667008331844\n",
      "epoch_53_acc 0.18181818181818182\n",
      "epoch_53_f1 0.8571428571428571\n",
      "\n",
      "0.8077537161963326\n",
      "epoch_56_acc 0.18181818181818182\n",
      "epoch_56_f1 0.8437500000000001\n",
      "\n",
      "0.8154578506946564\n",
      "epoch_59_acc 0.18181818181818182\n",
      "epoch_59_f1 0.8571428571428571\n",
      "\n",
      "0.8098053634166718\n",
      "epoch_62_acc 0.18181818181818182\n",
      "epoch_62_f1 0.8437500000000001\n",
      "\n",
      "0.8121841464723859\n",
      "epoch_65_acc 0.18181818181818182\n",
      "epoch_65_f1 0.8571428571428571\n",
      "\n",
      "0.8044635823794773\n",
      "epoch_68_acc 0.18181818181818182\n",
      "epoch_68_f1 0.8437500000000001\n",
      "\n",
      "0.8032482053552356\n",
      "epoch_71_acc 0.18181818181818182\n",
      "epoch_71_f1 0.8571428571428571\n",
      "\n",
      "0.8142895528248378\n",
      "epoch_74_acc 0.18181818181818182\n",
      "epoch_74_f1 0.8437500000000001\n",
      "\n",
      "0.8032418021133968\n",
      "epoch_77_acc 0.18181818181818182\n",
      "epoch_77_f1 0.8437500000000001\n",
      "\n",
      "0.8329827742917197\n",
      "epoch_80_acc 0.18181818181818182\n",
      "epoch_80_f1 0.8\n",
      "\n",
      "0.8027841448783875\n",
      "epoch_83_acc 0.18181818181818182\n",
      "epoch_83_f1 0.8125\n",
      "\n",
      "0.8228671465601239\n",
      "epoch_86_acc 0.18181818181818182\n",
      "epoch_86_f1 0.8125\n",
      "\n",
      "0.8123575150966644\n",
      "epoch_89_acc 0.18181818181818182\n",
      "epoch_89_f1 0.8\n",
      "\n",
      "0.8074013207639966\n",
      "epoch_92_acc 0.18181818181818182\n",
      "epoch_92_f1 0.7692307692307693\n",
      "\n",
      "0.8232704358441489\n",
      "epoch_95_acc 0.18181818181818182\n",
      "epoch_95_f1 0.7692307692307693\n",
      "\n",
      "0.7912251310689109\n",
      "epoch_98_acc 0.18181818181818182\n",
      "epoch_98_f1 0.8125\n",
      "\n",
      "final_acc 0.18181818181818182\n",
      "final_f1 0.8125\n",
      "best_acc 0.2727272727272727\n",
      "best_f1 0.8985507246376812\n"
     ]
    }
   ],
   "source": [
    "model, study, test = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW'],\n",
       " ['<s>', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW'],\n",
       " ['<s>', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW'],\n",
       " ['<s>', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW'],\n",
       " ['<s>', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW', 'YELLOW']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.temp = 1.0\n",
    "model.sample_qxy(model.py(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'gazzer', 'kiki', 'blicket', '</s>'],\n",
       " ['<s>', 'gazzer', '</s>'],\n",
       " ['<s>', 'dax', 'zup', 'fep', '</s>'],\n",
       " ['<s>', 'gazzer', 'kiki', 'blicket', 'tufa', '</s>'],\n",
       " ['<s>', 'gazzer', 'kiki', 'blicket', '</s>'],\n",
       " ['<s>', 'blicket', '</s>'],\n",
       " ['<s>', 'gazzer', 'zup', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'gazzer', 'zup', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'fep', 'zup', 'gazzer', 'kiki', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'gazzer', 'kiki', 'blicket', 'zup', 'fep', '</s>'],\n",
       " ['<s>', 'gazzer', 'kiki', 'blicket', 'tufa', '</s>'],\n",
       " ['<s>', 'gazzer', 'kiki', 'blicket', '</s>'],\n",
       " ['<s>', 'dax', '</s>'],\n",
       " ['<s>', 'fep', 'kiki', 'blicket', 'zup', 'dax', '</s>'],\n",
       " ['<s>', 'fep', 'zup', 'blicket', '</s>'],\n",
       " ['<s>', 'blicket', '</s>'],\n",
       " ['<s>', 'fep', 'kiki', 'blicket', 'tufa', '</s>'],\n",
       " ['<s>', 'gazzer', 'zup', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'blicket', 'tufa', 'kiki', 'gazzer', 'zup', 'gazzer', '</s>'],\n",
       " ['<s>', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'gazzer', 'tufa', '</s>'],\n",
       " ['<s>', 'gazzer', 'zup', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'gazzer', 'kiki', 'fep', '</s>'],\n",
       " ['<s>', 'gazzer', 'kiki', 'blicket', 'zup', 'fep', '</s>'],\n",
       " ['<s>', 'gazzer', 'kiki', 'blicket', '</s>'],\n",
       " ['<s>', 'blicket', 'zup', 'blicket', 'tufa', '</s>'],\n",
       " ['<s>', 'dax', 'kiki', 'blicket', '</s>'],\n",
       " ['<s>', 'dax', 'kiki', 'blicket', '</s>'],\n",
       " ['<s>', 'fep', '</s>'],\n",
       " ['<s>', 'dax', '</s>'],\n",
       " ['<s>', 'gazzer', 'zup', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'dax', 'zup', 'gazzer', '</s>'],\n",
       " ['<s>', 'gazzer', 'zup', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'fep', 'zup', 'gazzer', 'kiki', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'fep', 'kiki', 'blicket', 'zup', 'dax', '</s>'],\n",
       " ['<s>', 'gazzer', 'zup', 'fep', '</s>'],\n",
       " ['<s>', 'gazzer', 'zup', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'gazzer', '</s>'],\n",
       " ['<s>', 'dax', 'zup', 'gazzer', '</s>'],\n",
       " ['<s>', 'blicket', '</s>'],\n",
       " ['<s>', 'fep', 'tufa', '</s>'],\n",
       " ['<s>', 'blicket', '</s>'],\n",
       " ['<s>', 'blicket', '</s>'],\n",
       " ['<s>', 'dax', 'tufa', '</s>'],\n",
       " ['<s>', 'dax', 'kiki', 'fep', '</s>'],\n",
       " ['<s>', 'blicket', 'tufa', 'kiki', 'gazzer', 'zup', 'gazzer', '</s>'],\n",
       " ['<s>', 'dax', '</s>'],\n",
       " ['<s>', 'fep', 'tufa', '</s>'],\n",
       " ['<s>', 'dax', 'kiki', 'fep', '</s>'],\n",
       " ['<s>', 'fep', '</s>']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.temp = 1.0\n",
    "model.sample_px(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@//0 False 2 0 0\n",
      "['gazzer', 'zup', 'fep']\n",
      "gold ['PURPLE', 'RED', 'PURPLE']\n",
      "pred ['RED', 'PURPLE']\n",
      "False\n",
      "\n",
      "@//1 False 1 1 0\n",
      "['dax', 'tufa']\n",
      "gold ['GREEN', 'GREEN', 'GREEN']\n",
      "pred ['GREEN', 'RED']\n",
      "False\n",
      "\n",
      "@//2 False 3 1 1\n",
      "['gazzer', 'kiki', 'blicket', 'zup', 'fep']\n",
      "gold ['PINK', 'RED', 'PINK', 'PURPLE']\n",
      "pred ['PINK', 'GREEN', 'PINK', 'RED']\n",
      "False\n",
      "\n",
      "@//3 False 3 0 0\n",
      "['fep', 'zup', 'blicket']\n",
      "gold ['RED', 'PINK', 'RED']\n",
      "pred ['PINK', 'RED', 'PINK']\n",
      "False\n",
      "\n",
      "@//4 False 4 0 0\n",
      "['blicket', 'tufa', 'kiki', 'gazzer', 'zup', 'gazzer']\n",
      "gold ['PURPLE', 'PURPLE', 'PURPLE', 'PINK', 'PINK', 'PINK']\n",
      "pred ['PINK', 'PINK', 'PINK', 'PURPLE']\n",
      "False\n",
      "\n",
      "@//5 False 3 0 0\n",
      "['dax', 'kiki', 'fep']\n",
      "gold ['RED', 'GREEN']\n",
      "pred ['GREEN', 'RED', 'GREEN']\n",
      "False\n",
      "\n",
      "@//6 False 1 3 2\n",
      "['gazzer', 'zup', 'dax', 'tufa']\n",
      "gold ['PURPLE', 'GREEN', 'GREEN', 'GREEN', 'PURPLE']\n",
      "pred ['PINK', 'GREEN', 'PINK', 'RED']\n",
      "False\n",
      "\n",
      "@//7 True 2 0 0\n",
      "['gazzer', 'kiki', 'blicket']\n",
      "gold ['PINK', 'PURPLE']\n",
      "pred ['PINK', 'PURPLE']\n",
      "True\n",
      "\n",
      "@//8 False 1 1 0\n",
      "['gazzer', 'tufa']\n",
      "gold ['PURPLE', 'PURPLE', 'PURPLE']\n",
      "pred ['RED', 'PURPLE']\n",
      "False\n",
      "\n",
      "@//9 True 4 0 0\n",
      "['fep', 'kiki', 'blicket', 'tufa']\n",
      "gold ['PINK', 'PINK', 'PINK', 'RED']\n",
      "pred ['PINK', 'PINK', 'PINK', 'RED']\n",
      "True\n",
      "\n",
      "@//10 False 2 2 1\n",
      "['fep', 'zup', 'gazzer', 'kiki', 'dax', 'tufa']\n",
      "gold ['GREEN', 'GREEN', 'GREEN', 'RED', 'PURPLE', 'RED']\n",
      "pred ['PINK', 'GREEN', 'PINK', 'RED']\n",
      "False\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.18181818181818182, 0.8125)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, encode(test,model.vocab), vis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@//0 True 5 0 0\n",
      "['blicket', 'zup', 'blicket', 'tufa']\n",
      "gold ['PINK', 'PINK', 'PINK', 'PINK', 'PINK']\n",
      "pred ['PINK', 'PINK', 'PINK', 'PINK', 'PINK']\n",
      "True\n",
      "\n",
      "@//1 True 2 0 0\n",
      "['gazzer', 'kiki', 'fep']\n",
      "gold ['RED', 'PURPLE']\n",
      "pred ['RED', 'PURPLE']\n",
      "True\n",
      "\n",
      "@//2 True 3 0 0\n",
      "['blicket', 'tufa']\n",
      "gold ['PINK', 'PINK', 'PINK']\n",
      "pred ['PINK', 'PINK', 'PINK']\n",
      "True\n",
      "\n",
      "@//3 True 4 0 0\n",
      "['gazzer', 'kiki', 'blicket', 'tufa']\n",
      "gold ['PINK', 'PINK', 'PINK', 'PURPLE']\n",
      "pred ['PINK', 'PINK', 'PINK', 'PURPLE']\n",
      "True\n",
      "\n",
      "@//4 True 1 0 0\n",
      "['blicket']\n",
      "gold ['PINK']\n",
      "pred ['PINK']\n",
      "True\n",
      "\n",
      "@//5 True 4 0 0\n",
      "['fep', 'kiki', 'blicket', 'zup', 'dax']\n",
      "gold ['PINK', 'GREEN', 'PINK', 'RED']\n",
      "pred ['PINK', 'GREEN', 'PINK', 'RED']\n",
      "True\n",
      "\n",
      "@//6 True 3 0 0\n",
      "['dax', 'zup', 'fep']\n",
      "gold ['GREEN', 'RED', 'GREEN']\n",
      "pred ['GREEN', 'RED', 'GREEN']\n",
      "True\n",
      "\n",
      "@//7 True 4 0 0\n",
      "['blicket', 'zup', 'fep', 'kiki', 'fep']\n",
      "gold ['RED', 'PINK', 'RED', 'PINK']\n",
      "pred ['RED', 'PINK', 'RED', 'PINK']\n",
      "True\n",
      "\n",
      "@//8 True 3 0 0\n",
      "['fep', 'tufa']\n",
      "gold ['RED', 'RED', 'RED']\n",
      "pred ['RED', 'RED', 'RED']\n",
      "True\n",
      "\n",
      "@//9 True 1 0 0\n",
      "['gazzer']\n",
      "gold ['PURPLE']\n",
      "pred ['PURPLE']\n",
      "True\n",
      "\n",
      "@//10 True 1 0 0\n",
      "['dax']\n",
      "gold ['GREEN']\n",
      "pred ['GREEN']\n",
      "True\n",
      "\n",
      "@//11 True 2 0 0\n",
      "['dax', 'kiki', 'blicket']\n",
      "gold ['PINK', 'GREEN']\n",
      "pred ['PINK', 'GREEN']\n",
      "True\n",
      "\n",
      "@//12 True 1 0 0\n",
      "['fep']\n",
      "gold ['RED']\n",
      "pred ['RED']\n",
      "True\n",
      "\n",
      "@//13 True 3 0 0\n",
      "['dax', 'zup', 'gazzer']\n",
      "gold ['GREEN', 'PURPLE', 'GREEN']\n",
      "pred ['GREEN', 'PURPLE', 'GREEN']\n",
      "True\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, encode(study,model.vocab), vis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
